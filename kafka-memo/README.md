## Kafkaとは

- ストリームデータの扱いに長けてる。
    - ストリームデータとは時間とともに次々と発生する無限量のデータ。
- ストリームデータを高スループットかつ低レイテンシでリアルタイムに処理する。

## Kafkaの機能、役割

- メッセージング・バス
    - システム間でやりとりするデータ（イベント）を中継する
    - イベントがKafkaを中継することでイベントを送受信するシステム同士は互いの物理的な位置や処理タイミングを知る必要がない。この特徴により、Kafkaを中継するシステム同士を疎結合に保てる
    - 送受信形態はPublish/Subscribe型。送信側と受信側のシステムが1対多の関係
- ストレージ
    - Kafkaに送信されたイベントはログファイルに追記することで永続化される
    - ログファイルはKafkaが稼働するサーバー(Broker)のファイルシステムに書き込まれまれる
    - アプリケーションがKafkaからイベントを受信してもログファイルにイベントが残るため、何度でもイベントを再生することが可能
    - Kafkaはイベントだけでなく、受信側のシステムのイベント読み出し位置(Offset)も永続化する。読み出し位置を永続化することでイベントを受信するシステムは障害発生時も処理を途中から再開できるため、耐障害性の高いシステムとなる
    - イベントの永続方法はログファイルの末尾への追記となるため、データベースのように直接イベントを更新または削除できない。イベントを更新・削除する場合は、送信側のシステムから更新・削除イベントをKafkaに送信して、受信側で別途処理する必要がある
- ストリーム処理エンジン
    - ストリーム処理のバックエンドにKafkaを採用できる

## Kafkaが作られた目的

- データの生成(送信)するシステムと、データを消費(受信)するシステムを分離する
- 同じデータを複数のシステムで消費できるようにするためデータを永続化する
- データを高スループットのために最適化する
- データストリームの成長に合わせて、システムを水平にスケールできる

## ユースケース

- メッセージブローカー
    - システム間連携のデータハブ
    - 受信側の高負荷を抑える処理バッファ
- アナリティクス
    - ユーザーアクティビティの追跡
    - データウェアハウスのためのデータパイプライン
- 運用管理
    - ログの集約・フォワーディング
    - メトリクスの収集
- データ共有
    - バックエンドシステムのデータを要件に応じて別システムのデータストアに複製
    - 複数ドメイン間のデータ共有
- マイクロサービス
    - イベントソーシングやCQRSのためのイベントストア
    - サービス間連携のオーケストレーション(sagaパターン)
    - モノリスからサービスを分割するためのデータ移行レイヤー(stranglerパターン)
    

## イベント

- イベントはkafkaのメッセージ、レコードと同義
- イベント内には4つのデータがある
    - header
        - イベントのメタデータや補足情報を格納する
    - key
        - イベント格納先の振り分けや集約に使用されるデータ。
        - キーを設定しないことも可能
    - timestamp
        - イベントが作成された時刻。
    - value
        - イベントで処理したいデータ本体
        - 文字列、数値、JSONといった様々な形式のデータを値に指定可能

## TopicとPartition
- Partitionはkafkaクライアントアプリケーションから送信されたイベントを保持する
    - クライアントアプリケーションはPartitionごとにイベントを処理するため、Partition数を増やすことでシステム全体のスループットを高められる
- イベントのキーを元に特定のPartitionに割り振られて保存される
- 例えば、キーの1文字目が”a”から”j”はPartition0に、”k”から”t”はPartition1といった割り当てがされる
- Partitionに保存されたイベントにはPartition内で連続した番号が割り振られる。この番号をOffsetという
    - 同一のPartitionはイベントの順序が送信順であることが保証される
        - ※ただしtopic内のPartition間では順序は保証されない
    - 同一キーのイベントは同一のPartitionに割り振られる。
- レプリケーションによる冗長化
    - 各PartitionのイベントはKafkaが動作する複数のサーバ(Broker)にコピーされる
    - 一つのPartitionにつき、レプリカ内で書き込み可能なPartitionをリーダーと呼び、それ以外のコピーはフォロワーと呼ぶ。
    - リーダーレプリカのBrokerに障害が発生した場合、別のBrokerにいるフォロワーのPartitionがリーダーに昇格することで処理を続行させる
 
    ## ProducerとConsumer
    
    - Consumer
        - イベント呼び出し後、Partitionごとの処理済みOffsetを記録するコミットを行う
        - Offsetをコミットしておくことで、何らかの理由でConsumerが停止した場合も次の起動時に以前のコミット済みOffsetからPartition内のイベントを読み直せる
        - ただしOffsetのコミット前にConsumerが停止すると、最新のコミットから停止直前まで読み取ったOffsetのイベントを2回読み取ることになるため、2回以上イベントを読みとっても問題にならないようConsumerの処理を冪等にしておく
        - 1つ以上のConsumerをグルーピングしたConsumerGroupを構成することで、Topicから受信するイベントを負荷分散可能
            - ConsumerGroup内で1つのPartitionにつき1つのConsumeしかイベントを呼び出せないため、ConsumerGroup内で負荷分散可能なConsumeは最大Partition数まで
        
        ![スクリーンショット 2024-01-25 0.40.00.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/7a7e5864-a462-4ade-8192-955b500f68b1/67212c21-b6d0-410a-ae57-dc9307fbdc87/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2024-01-25_0.40.00.png)
        
        - ConsumerGroupのConsumerの数が増減した場合、ConsumerへのPartitionの際割り当て(リバランス)が自動的に行われる
        
    
    ## BrokerとZookeeper
    
    - Brokerはkafkaがインストールされ、プロセスが稼働するサーバー
        - ProducerとConsumerがイベントを送受信する物理的な宛先はBroker
        - Brokerでクラスタを組むことで冗長化できる
        - Partitionを複製するレプリカ数の最大値はBrokerの数と等しくなる
    - Zookeeper
        - 以下の情報を保持している
            - Topicの一覧
            - Topicの設定値
            - Partitionの状態
            - Brokerの一覧
            - BrokerのACL(Access Control List)の設定値
    - kafkaを動作するためにZookeeperは必須だったが、kafka2.8以降Kafkaクラスタを起動するモードが使用可能となった。このモードはZookeeperに保存されていたメタデータを全てBrokerで管理できるようになった
